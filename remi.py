import os
import requests
from flask import Flask, request, jsonify
from llmproxy import generate
from dotenv import load_dotenv  

app = Flask(__name__)

# Load API Key from .env file
load_dotenv()
API_KEY = os.getenv("YELP_API_KEY")   
YELP_API_URL = "https://api.yelp.com/v3/businesses/search"

# Single user session
session = {
    "state": "conversation",
    "history": [],
    "preferences": {"cuisine": None, "budget": None, "location": None, "occasion": None}
}

# def conversation_agent_llm(message):
#     print("conversation agent")
#     """Handles user conversation to gather details like cuisine, budget, and location."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are a friendly restaurant assistant named REMI ğŸ½ï¸.
#             Your job is to engage users in a natural conversation to gather their restaurant preferences.
            
#             - If the user hasn't provided cuisine, budget, or location, ask about them in a casual way.
#             - Infer details from context and suggest reasonable options.
#             - Always confirm what you have so far.
#             - for the budget store it as a number 1-4 according to this scale - "cheap": "1", "mid-range": "2", "expensive": "3", "fine dining": "4"
#             - If all required details (cuisine, budget, location) are collected, respond with "done" AND NOTHING ELSE
#             - DO NOT RECOMMEND RESTAURANTS AT ALL  
#         """,
#         query=f"User input: '{message}'\nCurrent known details: {session['preferences']}",
#         temperature=0.7,
#         lastk=10,
#         session_id="remi-conversation",
#         rag_usage=False
#     )
#     response_text = response.get("response", "âš ï¸ Sorry, I couldn't process that. Could you rephrase?").strip()

#     # if response_text.lower() == "done":
#     #     print("hello")
#     #     return control_agent_llm("done")  # Trigger control agent

#     return response_text  # Otherwise, return normal conversation response
def conversation_agent_llm(message):
    print("conversation agent")
    
    response = generate(
        model="4o-mini",
        system="""
            You are a friendly restaurant assistant named REMI ğŸ½ï¸.
            Your job is to engage users in a natural conversation to gather their restaurant preferences.

            - If the user hasn't provided cuisine, budget, or location, ask about them in a casual way.
            - Infer details from context and suggest reasonable options.
            - Always confirm what you have so far.
            - Store the budget as a number 1-4 according to this scale: 
              "cheap": "1", "mid-range": "2", "expensive": "3", "fine dining": "4"
            - If all required details (cuisine, budget, location) are collected, respond with exactly:
              "done | {cuisine} | {budget} | {location}" 
              - Ensure that the response format is strict to allow parsing.
        """,
        query=f"User input: '{message}'\nCurrent known details: {session['preferences']}",
        temperature=0.7,
        lastk=10,
        session_id="remi-conversation",
        rag_usage=False
    )

    response_text = response.get("response", "âš ï¸ Sorry, I couldn't process that. Could you rephrase?").strip()

    # ğŸ›‘ If REMI outputs "done", extract and store the preferences
    if response_text.lower().startswith("done |"):
        print(f"âœ… Extracted completion message: {response_text}")

        try:
            _, cuisine, budget, location = response_text.split(" | ")

            # Store extracted values in session
            session["preferences"]["cuisine"] = cuisine
            session["preferences"]["budget"] = budget
            session["preferences"]["location"] = location

            print(f"ğŸŸ¢ Preferences Updated in Session: {session['preferences']}")

        except ValueError:
            print("ğŸš¨ ERROR: Failed to parse 'done' response format. Ignoring update.")

        return "done"  # Return "done" to trigger search in control agent

    return response_text  # Otherwise, continue conversation

def control_agent_llm(message):
    print("control agent")
    
    # ğŸŸ¢ Ensure all required fields exist before proceeding
    if (
        session["preferences"]["cuisine"]
        and session["preferences"]["budget"]
        and session["preferences"]["location"]
    ):
        print(f"âœ… All preferences available, triggering search: {session['preferences']}")
        return search_restaurants()

    # Otherwise, query the LLM to decide next step
    response = generate(
        model="4o-mini",
        system="""
            You are an AI agent managing a restaurant recommendation assistant.
            Your job is to decide the best next step based on the user's input.

            - If the conversation agent responds with "done", respond with "search_restaurant".
            - Otherwise, respond with "continue".
        """,
        query=f"User input: '{message}'\nCurrent session: {session['preferences']}",
        temperature=0.0,
        lastk=10,
        session_id="remi-control",
        rag_usage=False
    )

    result = response.get("response", "").strip().lower()
    
    print(f"ğŸŸ¡ Preferences Before Search: {session['preferences']}")

    if result == "search_restaurant":
        print('âœ… Triggering restaurant search...')
        return search_restaurants()

    return "continue"

# def control_agent_llm(message):
#     print("control agent")
#     """Acts as REMI's control center, deciding whether to continue conversation or trigger restaurant search."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are an AI agent managing a restaurant recommendation assistant.
#             Your job is to decide the best next step based on the user's input.

#             - If the conversation agent responds with "done", respond with "search_restaurant".
#             - Otherwise, respond with "continue".
#         """,
#         query=f"User input: '{message}'\nCurrent session: {session['preferences']}",
#         temperature=0.0,
#         lastk=10,
#         session_id="remi-control",
#         rag_usage=False
#     )

#     result = response.get("response", "").strip().lower()

#     print(f"ğŸŸ¡ Preferences Before Search: {session['preferences']}")

#     if result == "search_restaurant":
#         print('hello')
#         return search_restaurants()

#     return "continue"  # Either "continue" or "search_restaurant"

def search_restaurants():
    """Searches for a restaurant based on user preferences using Yelp API."""
    print('âœ… Entering search_restaurants()')

    # Extract values safely
    cuisine = session["preferences"].get("cuisine", "").strip()
    budget = session["preferences"].get("budget", "").strip()
    location = session["preferences"].get("location", "").strip()

    # ğŸ›‘ Debugging: Print session data
    print(f"ğŸŸ¢ Preferences Passed to Yelp API: Cuisine={cuisine}, Budget={budget}, Location={location}")

    # ğŸ”´ If preferences are missing, print error message
    if not cuisine or not budget or not location:
        print("ğŸš¨ ERROR: Missing required fields in session before calling Yelp API.")
        return "âš ï¸ Missing details! Please make sure you've provided cuisine, budget, and location."

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "accept": "application/json"
    }

    params = {
        "term": cuisine,
        "location": location,
        "price": budget,  # Yelp API uses 1 (cheap) to 4 (expensive)
        "limit": 1,  
        "sort_by": "best_match"
    }

    print(f"ğŸ”µ Sending API Request to Yelp with Params: {params}")

    response = requests.get(YELP_API_URL, headers=headers, params=params)
    print(f"ğŸŸ  Yelp API Response Status: {response.status_code}")

    if response.status_code == 200:
        data = response.json()
        print(f"ğŸŸ£ Raw API Response: {data}")

        if "businesses" in data and data["businesses"]:
            restaurant = data["businesses"][0]
            name = restaurant["name"]
            address = ", ".join(restaurant["location"]["display_address"])
            rating = restaurant["rating"]

            print(f"âœ… Found Restaurant: {name}, {rating}â­, {address}")
            return f"ğŸ½ï¸ Found **{name}** ({rating}â­) in {address} for {cuisine} cuisine within your budget!"
        else:
            print("âš ï¸ No restaurants found in Yelp API response.")
            return "âš ï¸ Sorry, I couldn't find a matching restaurant. Try adjusting your preferences!"
    else:
        print(f"ğŸš¨ Yelp API Error: {response.status_code} - {response.text}")
        return f"âš ï¸ Yelp API request failed. Error {response.status_code}: {response.text}"


@app.route('/query', methods=['POST'])
def main():
    """Handles user queries and initiates the restaurant recommendation process."""
    data = request.get_json()
    message = data.get("text", "").strip()

    print(f"Message received: {message}")

    # If user restarts, reset session
    if message.lower() in ["restart", "start over"]:
        session.update({
            "state": "conversation",
            "history": [],
            "preferences": {"cuisine": None, "budget": None, "location": None, "occasion": None}
        })
        return jsonify({"text": "ğŸ½ï¸ **FEEEELING HUNGRY?** REMI ğŸ§‘ğŸ»â€ğŸ³ IS HERE TO HELP YOU!\n\nTell us what you're looking for, and we'll help you **find and book a restaurant!**\n\nWhat type of food are you in the mood for?"})

    # Control agent decides next step
    decision = control_agent_llm(message)

    if decision == "search_restaurant":
        return jsonify({"text": search_restaurants()})

    # Continue gathering user details
    response_text = conversation_agent_llm(message)
    return jsonify({"text": response_text})


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)



# import os
# import requests
# from flask import Flask, request, jsonify
# from llmproxy import generate
# from dotenv import load_dotenv  

# app = Flask(__name__)

# # Load API Key from .env file
# load_dotenv()
# API_KEY = os.getenv("YELP_API_KEY")   

# YELP_API_URL = "https://api.yelp.com/v3/businesses/search"

# # Single user session
# session = {
#     "state": "conversation",
#     "history": [],
#     "preferences": {"cuisine": None, "budget": None, "location": None, "occasion": None}
# }

# def conversation_agent_llm(message):
#     print("conversation agent")
#     """Handles user conversation to gather details like cuisine, budget, and location."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are a friendly restaurant assistant named REMI ğŸ½ï¸.
#             Your job is to engage users in a natural conversation to gather their restaurant preferences.
            
#             - If the user hasn't provided cuisine, budget, or location, ask about them in a casual way.
#             - Infer details from context and suggest reasonable options.
#             - Always confirm what you have so far.
#             - If all required details (cuisine, budget, location) are collected, respond with "done" AND NOTHING ELSE
#             - DO NOT RECCOMEND RESTARAUNTS AT ALL  
#         """,
#         query=f"User input: '{message}'\nCurrent known details: {session['preferences']}",
#         temperature=0.7,
#         lastk=10,
#         session_id="remi-conversation",
#         rag_usage=False
#     )

#     return response.get("response", "âš ï¸ Sorry, I couldn't process that. Could you rephrase?").strip()


# def control_agent_llm(message):
#     print("control agent")
#     """Acts as REMI's control center, deciding whether to continue conversation or trigger restaurant search."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are an AI agent managing a restaurant recommendation assistant.
#             Your job is to decide the best next step based on the user's input.

#             - If the user hasn't provided cuisine, budget, AND location, respond with "continue".
#             - If all required details are collected, respond with "search_restaurant".
#         """,
#         query=f"User input: '{message}'\nCurrent session: {session['preferences']}",
#         temperature=0.0,
#         lastk=10,
#         session_id="remi-control",
#         rag_usage=False
#     )

#     result = response.get("response", "").strip().lower()

#     # Ensure all details are filled before transitioning to search
#     if session["preferences"]["cuisine"] and session["preferences"]["budget"] and session["preferences"]["location"]:
#         return "search_restaurant"

#     return result  # Either "continue" or "search_restaurant"


# def search_restaurants():
#     """Mocks a restaurant search based on user preferences."""

#     return f"ğŸ½ï¸ Found the best {session['preferences']['cuisine']} restaurant within your {session['preferences']['budget']} budget at {session['preferences']['location']}!"


# @app.route('/query', methods=['POST'])
# def main():
#     """Handles user queries and initiates the restaurant recommendation process."""
#     data = request.get_json()
#     message = data.get("text", "").strip()

#     print(f"Message received: {message}")

#     # If user restarts, reset session
#     if message.lower() in ["restart", "start over"]:
#         session.update({
#             "state": "conversation",
#             "history": [],
#             "preferences": {"cuisine": None, "budget": None, "location": None, "occasion": None}
#         })
#         return jsonify({"text": "ğŸ½ï¸ **FEEEELING HUNGRY?** REMI ğŸ§‘ğŸ»â€ğŸ³ IS HERE TO HELP YOU!\n\nTell us what you're looking for, and we'll help you **find and book a restaurant!**\n\nWhat type of food are you in the mood for?"})

#     # Control agent decides next step
#     decision = control_agent_llm(message)

#     if decision == "search_restaurant":
#         return jsonify({"text": search_restaurants()})

#     # Continue gathering user details
#     response_text = conversation_agent_llm(message)
#     return jsonify({"text": response_text})


# if __name__ == "__main__":
#     app.run(host="0.0.0.0", port=5001)


####################################################################


# import os
# import requests
# from flask import Flask, request, jsonify
# from llmproxy import generate

# app = Flask(__name__)

# # Single user session
# session = {
#     "state": "conversation",
#     "history": [],
#     "preferences": {"cuisine": None, "budget": None, "location": None}
# }

# def conversation_agent_llm(message):
#     """Handles user conversation to gather details like cuisine, budget, and location."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are a friendly restaurant assistant named REMI ğŸ½ï¸.
#             Your job is to engage users in a natural conversation to gather their restaurant preferences.
#             Make it feel very conversational and casual
#             Please ask the user what occasion they are dining for 
#             Use emojis to make it more fun!
#             Be nice and welcoming! 
            
#             - If the user hasn't provided cuisine, budget, or location, ask about them in a casual way.
#             - Infer details from context and suggest reasonable options.
#             - If all details are collected, respond with "done".
#         """,
#         query=f"User input: '{message}'\nCurrent known details: {session['preferences']}",
#         temperature=0.7,
#         lastk=10,
#         session_id="remi-conversation",
#         rag_usage=False
#     )

#     return response.get("response", "âš ï¸ Sorry, I couldn't process that. Could you rephrase?").strip()


# def control_agent_llm(message):
#     """Acts as REMI's control center, deciding whether to continue conversation or trigger restaurant search."""
    
#     response = generate(
#         model="4o-mini",
#         system="""
#             You are an AI agent managing a restaurant recommendation assistant.
#             Your job is to decide the best next step based on the user's input.

#             - If the user hasn't provided cuisine, budget, AND location, respond with "continue".
#             - If all required details are collected, respond with "search_restaurant".
#         """,
#         query=f"User input: '{message}'\nCurrent session: {session['preferences']}",
#         temperature=0.0,
#         lastk=10,
#         session_id="remi-control",
#         rag_usage=False
#     )

#     result = response.get("response", "").strip().lower()
#     return result


# def search_restaurants():
#     """Mocks a restaurant search based on user preferences."""
#     return f"ğŸ½ï¸ Found the best {session['preferences']['cuisine']} restaurant within your {session['preferences']['budget']} budget at {session['preferences']['location']}!"


# @app.route('/query', methods=['POST'])
# def main():
#     """Handles user queries and initiates the restaurant recommendation process."""
#     data = request.get_json()
#     message = data.get("text", "").strip()

#     print(f"Message received: {message}")

#     # If user restarts, reset session
#     if message.lower() in ["restart", "start over"]:
#         session.update({
#             "state": "conversation",
#             "history": [],
#             "preferences": {"cuisine": None, "budget": None, "location": None}
#         })
#         return jsonify({"text": "ğŸ½ï¸ **FEEEELING HUNGRY?** REMI ğŸ§‘ğŸ»â€ğŸ³ IS HERE TO HELP YOU!\n\nTell us what you're looking for, and we'll help you **find and book a restaurant!**\n\nWhat type of food are you in the mood for?"})

#     # Control agent decides next step
#     decision = control_agent_llm(message)

#     if decision == "search_restaurant":
#         return jsonify({"text": search_restaurants()})

#     # Continue gathering user details
#     response_text = conversation_agent_llm(message)
#     return jsonify({"text": response_text})


# if __name__ == "__main__":
#     app.run(host="0.0.0.0", port=5001)
